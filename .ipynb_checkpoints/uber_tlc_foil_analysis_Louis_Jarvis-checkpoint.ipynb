{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Analysis of Uber TLC FOIL Data\n",
    "#### By Louis Jarvis\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd #high-performance, easy-to-use data structures and data analysis tools\n",
    "import geopandas #extends the datatypes used by pandas to allow spatial operations on geometric types\n",
    "import mapclassify as mc #Classification schemes for choropleth mapping\n",
    "import warnings\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import datetime\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from multiprocessing import cpu_count\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "from shapely.geometry import Point, Polygon\n",
    "from datetime import timedelta\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For plotting ride data throughout the notebook\n",
    "def plotRides(x, y, neighborhood):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.plot_date(x, y, '.', xdate=True, linestyle = '-')\n",
    "    plt.tick_params(length=6, width=2)\n",
    "    plt.axis([np.min(x), np.max(x), np.min(y), np.max(y)])\n",
    "    plt.xlabel('DateTime')\n",
    "    plt.ylabel('Number of Rides')\n",
    "    plt.title('Uber Rides in the ' + neighborhood + ' Neighborhood')\n",
    "    plt.show()\n",
    "\n",
    "#For plotting a map of the selected neighborhood\n",
    "def plotNeighborhood(neighborhood):\n",
    "    ax = neighborhoods.plot(edgecolor='k', facecolor='none', figsize=(15, 15))\n",
    "    ax.set(xlim=(-74.3, -73.6), ylim=(40.4, 41))\n",
    "    ridesJoinNeighborhood[ridesJoinNeighborhood['neighborhood'] == neighborhood].plot(ax=ax, color='blue')\n",
    "\n",
    "# sarima_forecast() will fit a model with a given configuration and make a one-step forecast\n",
    "def sarima_forecast(history, config):\n",
    "    order, sorder = config\n",
    "    # define model\n",
    "    model = SARIMAX(history, order=order, seasonal_order=sorder, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    # fit model\n",
    "    model_fit = model.fit(disp=False)\n",
    "    # make one step forecast\n",
    "    yhat = model_fit.predict(len(history), len(history))\n",
    "    return yhat[0]\n",
    "\n",
    "# train_test_split() function below implements this for a provided dataset and a specified number of time steps to use in the test set\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# The measure_rmse() function below will calculate the RMSE given a list of actual (the test set) and predicted values\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    test = test.reset_index(drop=True)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = sarima_forecast(history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "    result = None\n",
    "    # convert config to a key\n",
    "    key = str(cfg)\n",
    "    # show all warnings and fail on exception if debugging\n",
    "    if debug:\n",
    "        result = walk_forward_validation(data, n_test, cfg)\n",
    "    else:\n",
    "        # one failure during model validation suggests an unstable config\n",
    "        try:\n",
    "            # never show warnings when grid searching, too noisy\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                result = walk_forward_validation(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "    # check for an interesting result\n",
    "    if result is not None:\n",
    "        print(' > ' + \n",
    "              datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \n",
    "              ' Model[%s] %.3f' % (key, result)\n",
    "             )\n",
    "    return (key, result)\n",
    "\n",
    "# create a set of all sarima configs to try\n",
    "def sarima_configs(seasonal=[0]):\n",
    "    models = list()\n",
    "    # define config lists\n",
    "    p_params = [0, 1, 2]\n",
    "    d_params = [0, 1]\n",
    "    q_params = [0, 1, 2]\n",
    "    #t_params = ['n','c','t','ct']\n",
    "    P_params = [0, 1, 2]\n",
    "    D_params = [0, 1]\n",
    "    Q_params = [0, 1, 2]\n",
    "    m_params = seasonal\n",
    "    # create config instances\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for P in P_params:\n",
    "                    for D in D_params:\n",
    "                        for Q in Q_params:\n",
    "                            for m in m_params:\n",
    "                                cfg = [(p,d,q), (P,D,Q,m)]\n",
    "                                models.append(cfg)\n",
    "    return models\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    scores = None\n",
    "    if parallel:\n",
    "        # execute configs in parallel\n",
    "        executor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "        tasks = (delayed(score_model)(data, n_test, cfg, True) for cfg in cfg_list)\n",
    "        scores = executor(tasks)\n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    # remove empty results\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing & Formatting Uber TLC FOIL Ride Data\n",
    "**Rides**\n",
    "* Contains a list of all rides initiated in the New York City (NYC) area in September of 2014 in a GeoPandas GeoDataFrame\n",
    "* Only September 2014 data was included in the analysis due to computation resource constraints\n",
    "* Pickup time stamps (*pickupDateTime*) were rounded down to the nearest hour\n",
    "* *geometry* describes the ride's pickup location as a geodata CRS point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides = pd.read_csv(\"./data/uber-raw-data-sep14.csv\").pipe(geopandas.GeoDataFrame)\n",
    "rides['Date/Time'] = pd.to_datetime(rides['Date/Time'])\n",
    "rides['pickupDateTime'] = pd.to_datetime(rides['Date/Time'].dt.strftime(\"%Y-%m-%d %H:00:00\"))\n",
    "rides['geometry'] = list(zip(rides.Lon.astype(float), rides.Lat.astype(float)))\n",
    "rides['geometry'] = rides['geometry'].apply(Point)\n",
    "rides =  rides.drop(columns=['Lat', 'Lon', 'Base'])\n",
    "rides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neighborhoods**\n",
    "* A GeoDataFrame dataset that describe the physical boundries (in CRS polygons) of distinct neighborhoods within New York City\n",
    "* Will be used for grouping of ride pickup coordinates into discrete *locations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = geopandas.read_file(\"./data/Neighborhood_Tabulation_Areas.geojson\")\n",
    "neighborhoods.crs = rides.crs\n",
    "neighborhoods = neighborhoods.rename(index=str, columns={\"ntaname\": \"neighborhood\"})\n",
    "neighborhoods = neighborhoods.rename(index=str, columns={\"boro_name\": \"borough\"})\n",
    "neighborhoods = neighborhoods.drop(columns=['ntacode', 'shape_area', 'county_fips', 'shape_leng', 'boro_code'])\n",
    "neighborhoods.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Analysis  \n",
    "**ridesJoinNeighborhood** - Associating ride pickup coordinates with neighborhoods \n",
    "* By using geopandas sjoin function, we are able to match the pickup location of each ride with the neighborhood in which the ride was initiated\n",
    "* This information is used to group the series of ride pickup CRS coordinates into distinct *locations* (i.e., neighborhoods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridesJoinNeighborhood = geopandas.sjoin(rides, neighborhoods, op='within', how='left')\n",
    "ridesJoinNeighborhood.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ridesPerNeighborhood** - Aggregating ride data by neighborhood, hour\n",
    "* *ridesPerNeighborhood* groups and counts the number of rides that were initiated in each neighborhood per hour from *ridesJoinNeighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridesPerNeighborhood = ridesJoinNeighborhood.rename(index=str, columns={\"Date/Time\": \"count\"}).groupby(['pickupDateTime','neighborhood'], as_index=False)[['count']].count()\n",
    "ridesPerNeighborhood.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing a neighborhood to forecast**\n",
    "* The analysis will be performed per neighborhood due to the difference in seasonality across different neighborhoods (e.g., commercial centers experience different hours of peak activity relative to residential areas)\n",
    "* We will forecast the number of pickups per hour over the month of October 2014 for a specific, selected neighborhood\n",
    "  \n",
    "*Execute the following line to see a list of all NYC neighborhoods*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(neighborhoods['neighborhood'].sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Define the variable selectedNeighborhood below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedNeighborhood = 'East Village'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visualize the selected neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotNeighborhood(selectedNeighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ridesInSelectedNeighborhood** - a filtered DataFrame containing the ride counts per hour in the selected neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ridesInSelectedNeighborhood = ridesPerNeighborhood[ridesPerNeighborhood['neighborhood'] == selectedNeighborhood]\n",
    "ridesInSelectedNeighborhood = ridesInSelectedNeighborhood.drop(columns='neighborhood')\n",
    "ridesInSelectedNeighborhood = ridesInSelectedNeighborhood.reset_index(drop=True)\n",
    "plotRides(\n",
    "    ridesInSelectedNeighborhood['pickupDateTime'], \n",
    "    ridesInSelectedNeighborhood['count'],\n",
    "    selectedNeighborhood\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA forecasting\n",
    "* As seen in the plot above, there are recurring seasonal aspects to the plot with relative peaks observed during the night hours as well as during weekends\n",
    "* The Seasonal Autoregressive Integrated Moving Average (SARIMA) model is effective at forecasting univariate time series data that contain seasonal components [1]\n",
    "* This model was selected because of the seasonal nature of this time series dataset\n",
    "\n",
    "## Defining SARIMA hyperparamaters\n",
    "Configuring a SARIMA model requires selecting hyperparameters for both the trend and seasonal elements of the series\n",
    "\n",
    "    p: Trend autoregression order.\n",
    "    d: Trend difference order.\n",
    "    q: Trend moving average order.\n",
    "    P: Seasonal autoregressive order.\n",
    "    D: Seasonal difference order.\n",
    "    Q: Seasonal moving average order.\n",
    "    m: The number of time steps for a single seasonal period.\n",
    "\n",
    "The following line will perform a grid search of all possible combinations of hyperparameters to find the optimal configuration as described in [2]. The optimal hyperparameter configuration is identified by having the lowest Root Mean Square Error (RMSE) when comparing the modeled fit against the test data (consisting of the last 24 hours of the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ridesInSelectedNeighborhood['count']\n",
    "cfg_list = sarima_configs([24]) # period is set to 24 for this dataset because ride counts are aggregated on an hourly basis\n",
    "scores = grid_search(data, cfg_list, 24, True)\n",
    "\n",
    "for cfg, error in scores[:3]:\n",
    "    print(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting October 2014 rides using SARIMA model\n",
    "Train/ fit the SARIMA model using the optimal hyperparameter configuration identified above. The m variable is set to 168 (hours) here to better capture the seasonal behavior of ride counts over an entire *week*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Begin fitting: ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "my_order = (1, 0, 0) # model trend configuration (pdq)\n",
    "my_seasonal_order = (1, 1, 0, 168) # model seasonal trend configuration (PDQm)\n",
    "\n",
    "model = SARIMAX(\n",
    "    data, \n",
    "    order = my_order,\n",
    "    seasonal_order=my_seasonal_order\n",
    "    #,enforce_stationarity = False\n",
    "    #,enforce_invertibility = False\n",
    ")\n",
    "\n",
    "model_fit = model.fit()\n",
    "\n",
    "print('Complete fitting: ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast the next month (744 hours) of uber ride counts per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Begin forecasting: ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "yhat = round(model_fit.predict(start=len(data), end=len(data)+744)).astype(int)\n",
    "\n",
    "print('Complete forecasting: ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "d = []\n",
    "for i in range(len(yhat)-1):\n",
    "    d.append({'pickupDateTime': max(ridesInSelectedNeighborhood['pickupDateTime']) + timedelta(hours=i+1),\n",
    "            'count': yhat.iloc[i]})\n",
    "\n",
    "octRidesInSelectedNeighborhood = pd.DataFrame(d)\n",
    "plotRides(\n",
    "    octRidesInSelectedNeighborhood['pickupDateTime'], \n",
    "    octRidesInSelectedNeighborhood['count'],\n",
    "    selectedNeighborhood\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(octRidesInSelectedNeighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/  \n",
    "[2] https://machinelearningmastery.com/how-to-grid-search-sarima-model-hyperparameters-for-time-series-forecasting-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
